import os
import time
import json
import logging
from datetime import datetime
from kafka import KafkaProducer
import requests

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Configuration depuis les variables d'environnement
KAFKA_BOOTSTRAP_SERVERS = os.getenv('KAFKA_BOOTSTRAP_SERVERS', 'localhost:9092')
MATOMO_API_URL = os.getenv('MATOMO_API_URL', 'https://matomo.worldtempus.com')
MATOMO_TOKEN = os.getenv('MATOMO_TOKEN', '01dfcb049cd32e2de8a12cf419850308')
MATOMO_SITE_ID = os.getenv('MATOMO_SITE_ID', '6')
POLLING_INTERVAL = int(os.getenv('POLLING_INTERVAL', '5'))
KAFKA_TOPIC = 'raw-events'


def create_kafka_producer():
    """Cr√©er un producteur Kafka avec retry"""
    max_retries = 10
    retry_delay = 5
    
    for attempt in range(max_retries):
        try:
            producer = KafkaProducer(
                bootstrap_servers=KAFKA_BOOTSTRAP_SERVERS,
                value_serializer=lambda v: json.dumps(v).encode('utf-8'),
                acks='all',
                retries=3
            )
            logger.info(f"‚úÖ Connect√© √† Kafka: {KAFKA_BOOTSTRAP_SERVERS}")
            return producer
        except Exception as e:
            logger.warning(f"‚è≥ Tentative {attempt + 1}/{max_retries} - Kafka non disponible: {e}")
            if attempt < max_retries - 1:
                time.sleep(retry_delay)
            else:
                logger.error("‚ùå Impossible de se connecter √† Kafka apr√®s plusieurs tentatives")
                raise


def fetch_matomo_live_data():
    """
    R√©cup√®re les donn√©es live de Matomo API
    Endpoint: Live.getLastVisitsDetails
    """
    params = {
        'module': 'API',
        'method': 'Live.getLastVisitsDetails',
        'idSite': MATOMO_SITE_ID,
        'period': 'day',
        'date': 'today',
        'format': 'JSON',
        'token_auth': MATOMO_TOKEN,
        'showColumns': 'actionDetails,idVisit,visitIp,visitorId,fingerprint',
        'filter_sort_order': 'desc',
        'filter_limit': 10  # R√©cup√®re les 10 derni√®res visites
    }
    
    try:
        response = requests.get(MATOMO_API_URL, params=params, timeout=10)
        response.raise_for_status()
        data = response.json()
        logger.info(f"üìä R√©cup√©r√© {len(data)} visites depuis Matomo")
        return data
    except requests.exceptions.RequestException as e:
        logger.error(f"‚ùå Erreur lors de l'appel Matomo API: {e}")
        return []


def extract_action_details(visit_data):
    """
    Extrait les informations pertinentes des actionDetails
    Retourne une liste d'√©v√©nements avec url, pageId et timestamp
    """
    events = []
    
    for visit in visit_data:
        if 'actionDetails' not in visit:
            continue
            
        for action in visit['actionDetails']:
            # V√©rifier que c'est une action de type page view
            if action.get('type') != 'action':
                continue
                
            event = {
                'url': action.get('url', ''),
                'pageId': action.get('pageId', action.get('idpageview', '')),
                'timestamp': action.get('timestamp', int(time.time())),
                # 'serverTimePretty': action.get('serverTimePretty', ''),
                # 'pageTitle': action.get('pageTitle', ''),
                # 'timeSpent': action.get('timeSpent', 0),
                # # M√©tadonn√©es suppl√©mentaires
                # 'visitId': visit.get('idVisit', ''),
                # 'visitorId': visit.get('visitorId', ''),
                # 'country': visit.get('country', ''),
                # 'referrerUrl': action.get('referrerUrl', ''),
            }
            
            # Ne garder que les √©v√©nements avec URL valide
            if event['url']:
                events.append(event)
    
    return events


def clean_url(url):
    """
    Nettoie l'URL en supprimant les param√®tres de tracking et fragments
    """
    from urllib.parse import urlparse, urlunparse
    
    parsed = urlparse(url)
    # Reconstruire l'URL sans query string ni fragment
    cleaned = urlunparse((
        parsed.scheme,
        parsed.netloc,
        parsed.path,
        '',  # params
        '',  # query
        ''   # fragment
    ))
    return cleaned


def send_to_kafka(producer, events):
    """
    Envoie les √©v√©nements vers Kafka
    """
    sent_count = 0
    
    for event in events:
        try:
            # Nettoyer l'URL avant envoi
            event['url_cleaned'] = clean_url(event['url'])
            
            # Envoyer vers Kafka
            future = producer.send(KAFKA_TOPIC, value=event)
            # Attendre confirmation (bloquant)
            future.get(timeout=10)
            
            sent_count += 1
            logger.debug(f"üì§ Envoy√©: {event['url_cleaned']}")
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'envoi vers Kafka: {e}")
    
    if sent_count > 0:
        logger.info(f"‚úÖ {sent_count} √©v√©nements envoy√©s vers Kafka topic '{KAFKA_TOPIC}'")
    
    return sent_count


def main():
    """
    Boucle principale du producer
    """
    logger.info("üöÄ D√©marrage du Kafka Producer pour Matomo Analytics")
    logger.info(f"üìç Matomo API: {MATOMO_API_URL}")
    logger.info(f"üìç Kafka: {KAFKA_BOOTSTRAP_SERVERS}")
    logger.info(f"‚è±Ô∏è  Intervalle de polling: {POLLING_INTERVAL}s")
    
    # Cr√©er le producteur Kafka
    producer = create_kafka_producer()
    
    # Compteur pour stats
    total_events_sent = 0
    
    try:
        while True:
            logger.info(f"\n‚è∞ Polling Matomo API... [{datetime.now().strftime('%H:%M:%S')}]")
            
            # 1. R√©cup√©rer les donn√©es de Matomo
            visit_data = fetch_matomo_live_data()
            
            if not visit_data:
                logger.warning("‚ö†Ô∏è  Aucune donn√©e re√ßue de Matomo")
            else:
                # 2. Extraire les actionDetails
                events = extract_action_details(visit_data)
                
                if events:
                    # 3. Envoyer vers Kafka
                    sent = send_to_kafka(producer, events)
                    total_events_sent += sent
                    logger.info(f"üìä Total envoy√© depuis le d√©marrage: {total_events_sent}")
                else:
                    logger.info("‚ÑπÔ∏è  Aucun √©v√©nement √† envoyer")
            
            # Attendre avant le prochain polling
            time.sleep(POLLING_INTERVAL)
            
    except KeyboardInterrupt:
        logger.info("\nüõë Arr√™t demand√© par l'utilisateur")
    except Exception as e:
        logger.error(f"‚ùå Erreur fatale: {e}", exc_info=True)
    finally:
        logger.info("üîå Fermeture du producteur Kafka")
        producer.close()
        logger.info("üëã Producer arr√™t√© proprement")


if __name__ == '__main__':
    main()